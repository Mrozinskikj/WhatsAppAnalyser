{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import math\n",
    "import re\n",
    "from ipywidgets import IntRangeSlider, Output, Checkbox, HBox, VBox, RadioButtons, Button, Label, Layout, Text\n",
    "from IPython.display import display, clear_output\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "import requests\n",
    "stopwords_file = requests.get('https://raw.githubusercontent.com/Mrozinskikj/WhatsAppAnalyser/main/stopwords.txt').text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialisation Functions</h1>\n",
    "Read and convert chat data into organised structures. Define properties and helper functions for generating analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_type = \"apple\" # \"apple\" or \"android\"\n",
    "filename = \"chat.txt\"\n",
    "figscale = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>read chat data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = open(filename,\"r\", encoding=\"utf8\").read()\n",
    "if(chat_type==\"apple\"):\n",
    "    lines = chat.split(\"\\n\")[3:]\n",
    "elif(chat_type==\"android\"):\n",
    "    lines = chat.split(\"\\n\")\n",
    "\n",
    "chat_list = []\n",
    "media_list = []\n",
    "\n",
    "for l,line in enumerate(lines):\n",
    "    ascii = line.encode(\"ascii\", errors=\"ignore\").decode() # keep only ascii characters\n",
    "    try: # determine whether line is new chat or continuation of previous chat\n",
    "        if(chat_type==\"apple\"): # first line for apple determined by square brackets surrounding message date\n",
    "            firstline = ascii[0]==\"[\" and ascii[21]==\"]\"\n",
    "        elif(chat_type==\"android\"): #first line for android determined by comma separating date and time, and dash separating time and author\n",
    "            firstline = ascii[10]==\",\" and ascii[18]==\"-\"\n",
    "    except:\n",
    "        firstline = False\n",
    "    \n",
    "    if(firstline):\n",
    "        try: # ignore any broken chats\n",
    "            if(chat_type==\"apple\"):\n",
    "                date = datetime.datetime(int(ascii[7:11]),int(ascii[4:6]),int(ascii[1:3]),int(ascii[13:15]),int(ascii[16:18]),int(ascii[19:21]))\n",
    "                author = ascii[23:ascii.find(\":\",23)]\n",
    "                content = ascii[ascii.find(\":\",23)+2:]\n",
    "            elif(chat_type==\"android\"):\n",
    "                if(ascii.find(\":\",20)==-1): # ignore message if no author\n",
    "                    continue\n",
    "                date = datetime.datetime(int(ascii[6:10]),int(ascii[3:5]),int(ascii[0:2]),int(ascii[12:14]),int(ascii[15:17]))\n",
    "                author = ascii[20:ascii.find(\":\",20)]\n",
    "                content = ascii[ascii.find(\":\",20)+2:]\n",
    "            \n",
    "            if(content==\"image omitted\" or content==\"video omitted\" or content==\"sticker omitted\" or content==\"audio omitted\" or content==\"GIF omitted\" or content==\"<Media omitted>\"):\n",
    "                media_list.append({\"date\":date,\"auth\":author,\"cont\":content})\n",
    "            else:\n",
    "                chat_list.append({\"date\":date,\"auth\":author,\"cont\":content})\n",
    "        except:\n",
    "            pass\n",
    "    else: # if line is continuation of previous chat, append content to its entry\n",
    "        chat_list[-1][\"cont\"] += (\" \"+ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>separate chat data by author</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_chats = {}\n",
    "for chat in chat_list:\n",
    "    author_chats.setdefault(chat[\"auth\"], []).append(chat)\n",
    "\n",
    "author_media = {}\n",
    "for media in media_list:\n",
    "    author_media.setdefault(media[\"auth\"], []).append(media)\n",
    "\n",
    "for author in author_chats.keys(): # fill any gaps in dictionaries for authors which have either only sent chats or only sent media\n",
    "    if(author not in author_media.keys()):\n",
    "        author_media[author] = []\n",
    "for author in author_media.keys():\n",
    "    if(author not in author_chats.keys()):\n",
    "        author_chats[author] = []\n",
    "\n",
    "authors = list(author_chats.keys())\n",
    "if(chat_type==\"apple\"):\n",
    "    medias = {\"image omitted\":\"Image\",\n",
    "               \"video omitted\":\"Video\",\n",
    "               \"sticker omitted\":\"Sticker\",\n",
    "               \"audio omitted\":\"Audio\",\n",
    "               \"GIF omitted\":\"GIF\",}\n",
    "elif(chat_type==\"android\"): # android chat does not differentiate between media types\n",
    "    medias = {\"media omitted\":\"Media\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>define colours for plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = {\"total\":\"slategrey\",\n",
    "           \"messages_per_day\":\"tab:blue\",\n",
    "           \"words_per_message\":\"tab:purple\",\n",
    "           \"Image\":\"dodgerblue\",\n",
    "           \"Video\":\"darkslateblue\",\n",
    "           \"Sticker\":\"palevioletred\",\n",
    "           \"Audio\":\"mediumseagreen\",\n",
    "           \"GIF\":\"goldenrod\",\n",
    "           \"Media\":\"goldenrod\",\n",
    "           \"occurrences\":\"tab:red\",\n",
    "           \"alltime_lines\":\"indianred\",\n",
    "           \"major_grid\":\"gainsboro\",\n",
    "           \"minor_grid\":\"whitesmoke\",\n",
    "           \"year_grid\":\"silver\",\n",
    "           None:\"tab:blue\"}\n",
    "\n",
    "author_colours = {} # generate distinct colours for each author\n",
    "for a,author in enumerate(authors):\n",
    "    author_colours[author] = cm.get_cmap(\"tab10\")(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create dates for all timescales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = (chat_list[-1][\"date\"].date() - chat_list[0][\"date\"].date()).days + 1\n",
    "day_dates = [chat_list[0][\"date\"].date() + datetime.timedelta(days=i) for i in range(total_days)]\n",
    "first_date = day_dates[0]\n",
    "\n",
    "for d,date in enumerate(day_dates): # find position of first monday in dates list\n",
    "    if(date.weekday()==0):\n",
    "        first_monday=d\n",
    "        break\n",
    "week_dates = ([first_date] if first_monday!=0 else []) + [day_dates[first_monday] + datetime.timedelta(days=i) for i in range(0,total_days,7)] # week dates are the first day, then every subsequent monday\n",
    "\n",
    "total_months = (chat_list[-1][\"date\"].year - chat_list[0][\"date\"].year) * 12 + chat_list[-1][\"date\"].month - chat_list[0][\"date\"].month + 1\n",
    "month_dates = [chat_list[0][\"date\"].date()] + [datetime.date(chat_list[0][\"date\"].year,chat_list[0][\"date\"].month,1) + relativedelta(months=i) for i in range(1,total_months)]\n",
    "\n",
    "total_years = chat_list[-1][\"date\"].year - chat_list[0][\"date\"].year + 1\n",
    "year_dates = [chat_list[0][\"date\"].date()] + [datetime.date(chat_list[0][\"date\"].year,1,1) + relativedelta(years=i) for i in range(1,total_years)]\n",
    "\n",
    "dates = {\"Days\":day_dates,\"Weeks\":week_dates,\"Months\":month_dates,\"Years\":year_dates}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>convert data to appropriate timescale and trim to date range</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_index(i): # calculates index of new timescale relative to index of day timescale\n",
    "    if(timescale==\"Weeks\"):\n",
    "        return math.floor((i + 7-first_monday)/7) # week is calculated as 7 days from monday to monday\n",
    "    elif(timescale==\"Months\"):\n",
    "        return ((first_date + datetime.timedelta(days=i)).year - first_date.year) * 12 + (first_date + datetime.timedelta(days=i)).month - first_date.month # month is calculated as (year difference)*12 + (month difference)\n",
    "    elif(timescale==\"Years\"):\n",
    "        return (first_date + datetime.timedelta(days=i)).year - first_date.year\n",
    "\n",
    "def scale(data, average=False): # convert day sums to sums of any other timescale\n",
    "    if(timescale==\"Days\"): # don't convert if already days\n",
    "        return data[...,date_range[0]:date_range[1]+1] # trim last dimension to date\n",
    "\n",
    "    new_timescale = np.zeros(data.shape[0:-1]+(len(dates[timescale]),)) # new timescale is same shape as original data, apart from the last shrunken dimension\n",
    "\n",
    "    if(average): # average scaling is the average of all data values belonging to new timescale weighted by content sums of the given day\n",
    "        new_timescale_sums = np.zeros(data.shape[0:-1]+(len(dates[timescale]),)) # same shape as original data, apart from the last shrunken dimension\n",
    "\n",
    "        if(data.ndim==1):\n",
    "            sums = np.sum(content_sums[\"Message\"],axis=0) # message sums of all authors combined\n",
    "            for i in range(len(data)):\n",
    "                new_timescale[calculate_index(i)] += data[i] * sums[i] # multiply data by message sums\n",
    "                new_timescale_sums[calculate_index(i)] += sums[i]\n",
    "        elif(data.ndim==2):\n",
    "            sums = content_sums[\"Message\"] # message sums per author\n",
    "            for i in range(len(data[0])):\n",
    "                new_timescale[:,calculate_index(i)] += data[:,i] * sums[:,i] # multiply data by message sums\n",
    "                new_timescale_sums[:,calculate_index(i)] += sums[:,i]\n",
    "        \n",
    "        new_timescale = np.where(new_timescale_sums!=0, new_timescale/new_timescale_sums, 0) # divide data by message sums\n",
    "\n",
    "    else: # non-average scaling is the sum of all data values belonging to new timescale\n",
    "        if(data.ndim==1):\n",
    "            for i in range(len(data)):\n",
    "                new_timescale[calculate_index(i)] += data[i]\n",
    "        elif(data.ndim==2):\n",
    "            for i in range(len(data[0])):\n",
    "                new_timescale[:,calculate_index(i)] += data[:,i]\n",
    "        elif(data.ndim==3):\n",
    "            for i in range(len(data[0,0])):\n",
    "                new_timescale[:,:,calculate_index(i)] += data[:,:,i]\n",
    "    \n",
    "    return new_timescale[...,date_range[0]:date_range[1]+1] # trim last dimension to date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calculation functions</h1>\n",
    "Convert per-author chat data into a per-author daily representation of a statistic. Later used by plot functions to turn into finalised statistics ready for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of all separate content types</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_content_sums():\n",
    "    if(chat_type==\"apple\"): # individual list of sums for every message type\n",
    "        sums = {media:np.zeros((len(authors),len(dates[\"Days\"]))) for media in [\"Message\",\"Image\",\"Video\",\"Sticker\",\"Audio\",\"GIF\"]}\n",
    "    else:\n",
    "        sums = {media:np.zeros((len(authors),len(dates[\"Days\"]))) for media in [\"Message\",\"Media\"]}\n",
    "    \n",
    "    for a,author in enumerate(author_chats):\n",
    "        for message in author_chats[author]: # sum messages\n",
    "            sums[\"Message\"][a][(message[\"date\"].date() - dates[\"Days\"][0]).days] += 1\n",
    "        \n",
    "        for media in author_media[author]: # sum media\n",
    "            sums[medias[media[\"cont\"]]][a][(media[\"date\"].date() - dates[\"Days\"][0]).days] += 1\n",
    "    \n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of words in messages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_sums():\n",
    "    sums = np.zeros((len(authors),len(dates[\"Days\"]))) # daily sums of words for every author\n",
    "    for a,author in enumerate(authors):\n",
    "        for message in author_chats[author]:\n",
    "            sums[a, (message[\"date\"].date() - dates[\"Days\"][0]).days] += len(message[\"cont\"].split(\" \")) # adds number of words in message to daily sum\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of messages sent for every hour</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_by_hour():\n",
    "    sums = np.zeros((len(authors),24,len(dates[\"Days\"]))) # daily messages by hour for each author\n",
    "    for a,author in enumerate(author_chats):\n",
    "        for message in author_chats[author]:\n",
    "            sums[a, message[\"date\"].hour, (message[\"date\"].date() - dates[\"Days\"][0]).days] += 1\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily occurrences of a given search key</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occurrences():\n",
    "    global search\n",
    "    search = re.sub(r'[^a-zA-Z0-9\\s]', '', search.lower()) # search key is alphanumeric lowercase\n",
    "    sums = np.zeros((len(authors),len(dates[\"Days\"]))) # occurrences for each day for each author\n",
    "\n",
    "    for a, author in enumerate(author_chats):\n",
    "        for message in author_chats[author]:\n",
    "            message_alphanum = re.sub(r'[^a-zA-Z0-9\\s]', '', message[\"cont\"].lower()) # message is alphanumeric lowercase\n",
    "            sums[a,(message[\"date\"].date() - dates[\"Days\"][0]).days] += message_alphanum.count(search) # add occurrences of the search key\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sentiment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment():\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sums = np.zeros((len(authors),len(dates[\"Days\"])))\n",
    "    weights = np.zeros((len(authors),len(dates[\"Days\"])))\n",
    "\n",
    "    for a,author in enumerate(author_chats):\n",
    "        for message in author_chats[author]:\n",
    "            weight = len(re.split('[-.,:;!? ]', message[\"cont\"]))**0.5 # longer message receives an amplified sentiment score, with diminishing returns\n",
    "            score = sid.polarity_scores(message[\"cont\"])[\"compound\"] * weight # calculate sentiment of message- weighted\n",
    "            sums[a,(message[\"date\"].date() - dates[\"Days\"][0]).days] += score\n",
    "            weights[a,(message[\"date\"].date() - dates[\"Days\"][0]).days] += weight\n",
    "\n",
    "    sums = np.where(weights!=0, sums/weights, 0)\n",
    "        #sentiment[author] = [sums[i]/weights[i] if weights[i]!=0 else 0 for i in range(len(sums))] # divide each day of sentiment by day sum of weights to bring back to range of -1,1\n",
    "\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate most commonly used or most representative words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_words():\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set([re.sub(r'[^a-zA-Z0-9\\s]', '', word) for word in stopwords_file]) # filters common \"meaningless\" words\n",
    "    lemma_exceptions = {\"cos\",\"cus\"} # words which are exempt from lemmatisation\n",
    "\n",
    "\n",
    "    word_ranking = {} # ranking of words for each author. either frequency or representativeness\n",
    "    for author in author_chats:\n",
    "        ranking = {}\n",
    "        for message in author_chats[author]:\n",
    "            if(message[\"date\"].date()>=dates[timescale][date_range[0]] and message[\"date\"].date()<=dates[timescale][date_range[1]]):\n",
    "                added_lemmas = {} # dictionary storing how many of which lemmas have been added in the current message. used for scaling down the value of subsequent lemmas\n",
    "                words = re.split('[-.,:;!? ]', message[\"cont\"]) # split message into words by any punctuation\n",
    "                for word in words:\n",
    "                    word_alphanum = re.sub(r'[^a-zA-Z0-9\\s]', '', word.lower()) # convert word to only contain lowercase letters and numbers and spaces\n",
    "                    if(word_alphanum != \"\" and word_alphanum not in stop_words):\n",
    "                        if(word_alphanum not in lemma_exceptions):\n",
    "                            lemma = lemmatizer.lemmatize(word_alphanum)\n",
    "                        else:\n",
    "                            lemma = word_alphanum\n",
    "                        \n",
    "                        if(word_type==\"Representativeness\"): # if representativeness calculation, subsequent lemmas within the same message are scaled down in value\n",
    "                            added_lemmas[lemma] = added_lemmas.get(lemma,0) + 1\n",
    "                            scaled = added_lemmas[lemma]**-0.5\n",
    "                            ranking[lemma] = ranking.get(lemma,0) + scaled\n",
    "                        else: # if frequency calculation, every lemma is worth the same\n",
    "                            ranking[lemma] = ranking.get(lemma,0) + 1\n",
    "        \n",
    "        word_ranking[author] = dict(sorted(ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "\n",
    "    if(word_type==\"Representativeness\"):\n",
    "        total_word_ranking = {} # total ranking is sum of author rankings\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                total_word_ranking[word] = total_word_ranking.get(word,0) + word_ranking[author][word]\n",
    "        total_word_ranking = dict(sorted(total_word_ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                word_ranking[author][word] = math.log(word_ranking[author][word]) * (word_ranking[author][word]/total_word_ranking[word]) # author word usage over total usage scaled by log of author usage\n",
    "            \n",
    "            word_ranking[author] = dict(sorted(word_ranking[author].items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "            max_value = list(word_ranking[author].values())[0]\n",
    "            word_ranking[author] = {k: v / max_value for k, v in word_ranking[author].items()}\n",
    "\n",
    "    return word_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot helper functions</h1>\n",
    "Implement generic plot types (line plot, bar plot etc.) which visualise input data. Called by plot functions to create individual consitiuent axes of a full visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>line plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_ax(ax, data, labels, bipolar, title):\n",
    "    date_axis = dates[timescale][date_range[0]:date_range[1]+1]\n",
    "\n",
    "    if(len(date_axis)>50): # display point markers if little enough data\n",
    "        marker=\"none\"\n",
    "    else:\n",
    "        marker=\".\"\n",
    "\n",
    "    max_val = max([max([abs(point) for point in line]) for line in data]) if max([max([abs(point) for point in line]) for line in data])!=0 else 1 # maximum value in all data for axis limits\n",
    "    \n",
    "    for l,line in enumerate(data):\n",
    "        if(labels==[None]): # line colour, either total colour or author colour\n",
    "            colour = colours[\"total\"]\n",
    "        else:\n",
    "            colour = author_colours[labels[l]]\n",
    "        \n",
    "        ax.plot(date_axis, line, color=colour, label=labels[l], marker=marker, linewidth=1, zorder=3) # plot data\n",
    "        if(len(data)==1): # fill underneath line if one data point\n",
    "            ax.fill_between(date_axis, line, alpha=0.1, color=colour)\n",
    "\n",
    "    if(labels!=[None]): # plot legend if labels present\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.125), fontsize=8, ncol=100)\n",
    "    \n",
    "    ax.title.set_text(title)\n",
    "    if(not bipolar):\n",
    "        ax.set_ylim([0, max_val*1.05])\n",
    "    else:\n",
    "        ax.axhline(y=0, linewidth=0.5, color=\"black\", zorder=3)\n",
    "        ax.set_ylim([-max_val*1.05, max_val*1.05])\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "    ax.grid(True,zorder=0,color=colours[\"major_grid\"],linewidth = 1)\n",
    "    ax.grid(True, zorder=0,color=colours[\"minor_grid\"], which='minor')\n",
    "    ax.xaxis.grid(which='minor', visible=False)\n",
    "    for year in dates[\"Years\"]: # year grids\n",
    "        ax.axvline(x=year, color=colours[\"year_grid\"], zorder=2, linewidth=1)\n",
    "    if(date_range[0]!=date_range[1]):\n",
    "        ax.set_xlim([min(date_axis), max(date_axis)]) # set x axis to date limits (if more than 1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeltext(value,ratio,prefix=True): # generate the label text\n",
    "    prefix=\"1:\" if ratio and prefix else \"\"\n",
    "    if(ratio): \n",
    "        if(value!=0):\n",
    "            value=1/value\n",
    "        else:\n",
    "            return prefix+\"∞\"\n",
    "    return prefix+str(f'{float(f\"{value:.3g}\"):g}')\n",
    "\n",
    "def addlabels(ax,data,alltime_data,ratio,date): # adds a label for the value rounded to 3 significant figures\n",
    "    width = 0.9 / len(data)\n",
    "    shift = np.linspace(width*(len(data)-1)/2, -width*(len(data)-1)/2, len(data)) # calculate y offset for multiple bars\n",
    "\n",
    "    for bs, bars in enumerate(data): # iterate through every collection of bars (for multi-bar plots)\n",
    "        for b, bar in enumerate(bars): # iterate through every bar\n",
    "            if(np.max(data)!=0):\n",
    "                if(bar/np.max(data)>0.2): # label inside of bar if enough space\n",
    "                    colour=\"white\"\n",
    "                    align=\"right\"\n",
    "                else: # label outside of bar if not enough space\n",
    "                    colour=\"black\"\n",
    "                    align=\"left\"\n",
    "            else:\n",
    "                colour=\"black\"\n",
    "                align=\"left\"\n",
    "            \n",
    "            if(date_range!=(0,len(dates[timescale])-1) and date==True): # write fraction of all-time value if subsection of date selected\n",
    "                label = labeltext(bar,ratio)+\" / \"+labeltext(alltime_data[bs][b],ratio,prefix=False)\n",
    "            else:\n",
    "                label = labeltext(bar,ratio)\n",
    "            \n",
    "            ax.text(bar, b+shift[bs]-0.025, label, va=\"center\", ha=align, color=colour, fontsize=7)\n",
    "\n",
    "def bar_ax(ax, title, data, alltime_data, authors, ratio, colour_ids, labels, bipolar):\n",
    "    ax.title.set_text(title)\n",
    "    if(len(data)!=0):\n",
    "        y = np.arange(len(authors)) # y axis is number of authors\n",
    "        width = 0.9 / len(data)\n",
    "        shift = np.linspace(width*(len(data)-1)/2, -width*(len(data)-1)/2, len(data)) # calculate y offset for multiple bars\n",
    "\n",
    "        bar_charts = []\n",
    "        \n",
    "        for i,item in enumerate(data): # plot all bars\n",
    "            bar_charts.append(ax.barh(y+shift[i], item, width, color=colours[colour_ids[i]], label=labels[i], zorder=2))\n",
    "        \n",
    "        if(colour_ids==[None]): # if colours not provided, sets each individual bar to author colour (guaranteed only one bar per author)\n",
    "            colour_ids = [author_colours[a] for a in display_authors]\n",
    "            for i in range(len(bar_charts[0])):\n",
    "                bar_charts[0][i].set_color(colour_ids[i])\n",
    "        \n",
    "        if(date_range!=(0,len(dates[timescale])-1)): # draw all-time lines if subsection of date selected\n",
    "            for bs, bars in enumerate(bar_charts):\n",
    "                for b, bar in enumerate(bars):\n",
    "                    ax.vlines(alltime_data[bs][b],ymin=bar.get_y(),ymax=bar.get_y() + bar.get_height(),colors='white',linewidth=0.5,path_effects=[pe.Stroke(linewidth=2, foreground=colours[\"alltime_lines\"]), pe.Normal()])\n",
    "        \n",
    "        max_val = np.max(np.hstack((data,alltime_data))) if np.max(np.hstack((data,alltime_data)))!=0 else 1 # maximum value in all data and alltime data combined for axis limit\n",
    "        ax.set_xlim(0,max_val*1.05)\n",
    "\n",
    "        if(bipolar): # set axis limit to maximum on both sides, centred at 0\n",
    "            ax.set_xlim(-max_val*1.05,max_val*1.05)\n",
    "            ax.axvline(x=0, linewidth=0.5, color=\"black\")\n",
    "        \n",
    "        ax.xaxis.grid(color=colours[\"major_grid\"])\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(authors)\n",
    "        ax.set_yticks(np.arange(-0.5, len(authors), 1), minor=True)\n",
    "        ax.tick_params(axis='y', which='minor', length=0)\n",
    "        ax.grid(which='minor', color=colours[\"major_grid\"], zorder=0)\n",
    "        if(None not in labels):\n",
    "            ax.legend(fontsize=8)\n",
    "        \n",
    "        addlabels(ax, data, alltime_data, ratio, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>polar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polar(fig, data, labels, clock, total):\n",
    "    if(clock==\"pm\"):\n",
    "        size = [1.2, 0, 1, 1] # plot size\n",
    "        tick_labels = range(12,24) # tick labels\n",
    "        ring = -3 # inner ring size\n",
    "    else:\n",
    "        size = [1.4, 0.2, 0.6, 0.6] # plot size\n",
    "        tick_labels = range(0,12) # tick labels\n",
    "        ring = -1.4 # inner ring size\n",
    "    if(not total): # total and individual rings are placed side-by-side\n",
    "        size[0]+=1.2\n",
    "\n",
    "    ax = fig.add_axes(size, polar=True) # place inner plot of size dependent on whether inner am or outer pm\n",
    "\n",
    "    ax.set_rorigin(ring) # inner ring size\n",
    "    ax.set_yticks([]) # hide grid - added manually to be polygonal\n",
    "    ax.set_ylim([0,1]) # plots values of range 0-1\n",
    "    ax.set_xticks(np.linspace(0, 2*np.pi, 12, endpoint=False)) # 12 ticks\n",
    "    ax.set_xticklabels(tick_labels) # tick labels\n",
    "    ax.tick_params(pad=-2.5) # label distance from ticks\n",
    "    ax.set_theta_direction(-1) # clockwise\n",
    "    ax.set_theta_offset(np.pi/2.0) # start from top\n",
    "    ax.spines['polar'].set_visible(False) # hide outer border - added manually to be polygonal\n",
    "    \n",
    "    theta = np.linspace(0, 2*np.pi, 13) # plot new polygonal gridlines with 5 segments\n",
    "    for i in range(0,6):\n",
    "        if(i==0 or i==5):\n",
    "            ax.plot(theta, [i/5]*13, color='black', linewidth=1)\n",
    "        else:\n",
    "            ax.plot(theta, [i/5]*13, color=colours[\"major_grid\"], linewidth=0.5)\n",
    "    ax.axvline(x = 0, color='black') # axis break at 12pm/am\n",
    "\n",
    "    for i,item in enumerate(data): # plot lines\n",
    "        if(total): # line colour\n",
    "            colour = colours[\"total\"]\n",
    "        else:\n",
    "            colour = author_colours[labels[i]]\n",
    "\n",
    "        if(clock==\"pm\"):\n",
    "            hours = np.hstack((item[12:24],[item[0]])) # 12pm-12am if pm\n",
    "        else:\n",
    "            hours = item[0:13] # 12am-12pm if am\n",
    "        ax.plot(theta, hours, marker='.', markevery=range(0,12), color=colour, label=labels[i], linewidth=1)\n",
    "        if(len(data)==1):\n",
    "            ax.fill(theta, hours, alpha=0.1, color=colour)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>list plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_ax(ax,words,freqs,title,word_colour):\n",
    "    ax.barh(words,freqs,color=word_colour) # plot\n",
    "    ax.title.set_text(title)\n",
    "    ax.invert_yaxis() # top to bottom\n",
    "    ax.set_ylim([display_amount,-1]) # prevent axis padding\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    addlabels(ax,[freqs],None,False,False)\n",
    "    if(len(words)==0): # hide tick labels if no words\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_yticks(np.arange(-0.5, display_amount, 1), minor=True)\n",
    "    ax.grid(which='minor', color=colours[\"major_grid\"], zorder=0)\n",
    "    for j in range(display_amount): # word ranking label\n",
    "        ax.text(ax.get_xlim()[1],j,j+1, va=\"center\", ha=\"right\", color=colours[\"year_grid\"], fontsize=7, zorder=0)\n",
    "    for j in range(display_amount,0,-10): # separator for every 10 words\n",
    "        ax.axhline(y=j-1.5, color=colours[\"year_grid\"], zorder=2, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot functions</h1>\n",
    "Initialise plot objects, convert daily representation of statistic into finalised statistic, and call plot helper functions to fill axes and create a full visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author sums of content as 2 line plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activity():\n",
    "    fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(12*figscale,4*figscale))\n",
    "\n",
    "    display = np.stack([content_sums[content] for content in display_content]) # 3d array of every content type to be displayed\n",
    "    individual_data = scale(np.sum(display, axis=0)[authors_index]) # 2d array- sum of all display content per day per author\n",
    "    total_data = scale(np.sum(np.sum(display, axis=0), axis=0)) # 1d array - sum of all authors\n",
    "    \n",
    "    line_ax(ax[0], [total_data], [None], False, \"Total Activity\")\n",
    "    line_ax(ax[1], individual_data, display_authors, False, \"Individual Activity\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot messages per day, words per message, and media to message ratio as 3 bar plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_activity():\n",
    "    # calculate daily sums of messages and words, per author, as a list\n",
    "    num_days = (dates[timescale][date_range[1]]-dates[timescale][date_range[0]]).days+1\n",
    "    messagesums = np.sum(scale(content_sums[\"Message\"][authors_index]), axis=1) # 1d array of messages summed across all days per author\n",
    "    messages_per_day = np.where(messagesums!=0, messagesums/num_days, 0) # 1d array of messages / days\n",
    "    all_messagesums = np.sum(content_sums[\"Message\"][authors_index], axis=1) # 1d array of messages summed across all days per author\n",
    "    all_messages_per_day = np.where(all_messagesums!=0, all_messagesums/total_days, 0) # 1d array of messages / days\n",
    "\n",
    "    wordsums = np.sum(scale(word_sums[authors_index]), axis=1) # 1d array of words summed across all days per author\n",
    "    words_per_message = np.where(messagesums!=0, wordsums/messagesums, 0) # 1d array of words / messages\n",
    "    all_wordsums = np.sum(word_sums[authors_index], axis=1) # 1d array of words summed across all days per author\n",
    "    all_words_per_message = np.where(all_messagesums!=0, all_wordsums/all_messagesums, 0) # 1d array of words / messages\n",
    "\n",
    "    displaymedia = np.stack([content_sums[media][authors_index] for media in display_media]) # 3d array of every media type to be displayed\n",
    "    mediasums = np.sum(scale(displaymedia), axis=2) # 2d array of every media type for every author, summed across all days\n",
    "    media_to_message = np.where(messagesums!=0,mediasums/messagesums,0) # 2d array of media sums / message sums\n",
    "    all_mediasums = np.sum(displaymedia, axis=2) # 2d array of every media type for every author, summed across all days\n",
    "    all_media_to_message = np.where(all_messagesums!=0,all_mediasums/all_messagesums,0) # 2d array of media sums / message sums\n",
    "\n",
    "    initials = [a[0] for a in display_authors] # all charts after first display only first letter of author\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12*figscale,4*figscale))\n",
    "\n",
    "    bar_ax(ax[0], \"Average Daily Messages\",    [messages_per_day],  [all_messages_per_day],  display_authors,  False, [\"messages_per_day\"],  [None],        False)\n",
    "    bar_ax(ax[1], \"Average Words per Message\", [words_per_message], [all_words_per_message], initials,         False, [\"words_per_message\"], [None],        False)\n",
    "    bar_ax(ax[2], \"Media to Message Ratio\",    media_to_message,    all_media_to_message,    initials,         True,  display_media,         display_media, False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author messages by hour as 2 sets of AM-PM polar plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_messages_by_hour():\n",
    "    fig = plt.figure(figsize=(4*figscale, 4*figscale))\n",
    "\n",
    "    individual_data = np.sum(scale(messages_by_hour[authors_index]),axis=2) # 2d array of messages by hour summed across all days per author\n",
    "    individual_data_normalised = np.where(np.max(individual_data)!=0, individual_data/np.max(individual_data), 0) # normalised so max value = 1\n",
    "\n",
    "    total_data = np.sum(np.sum(scale(messages_by_hour),axis=2),axis=0) # 1d array of messages by hour summed across all days and authors\n",
    "    total_data_normalised = np.where(np.max(total_data)!=0, total_data/np.max(total_data), 0) # normalised so max value = 1\n",
    "\n",
    "    ax = plot_polar(fig,[total_data_normalised],[None],\"pm\",True)\n",
    "    ax.set_title(\"Total Messages by Hour\")\n",
    "    plot_polar(fig,[total_data_normalised],[None],\"am\",True)\n",
    "\n",
    "    ax = plot_polar(fig,individual_data_normalised,display_authors,\"pm\",False)\n",
    "    ax.set_title(\"Individual Messages by Hour\")\n",
    "    ax.legend(loc='center right', bbox_to_anchor=(1.425, 0.5), fontsize=8)\n",
    "    plot_polar(fig,individual_data_normalised,display_authors,\"am\",False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author occurrences of a given search key as 2 line plots and a summed bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occurrences():\n",
    "    fig = plt.figure(figsize=(12*figscale,4*figscale))\n",
    "    gs = gridspec.GridSpec(2,7)\n",
    "    ax1 = plt.subplot(gs[0, 0:5])\n",
    "    ax2 = plt.subplot(gs[1, 0:5])\n",
    "    ax3 = plt.subplot(gs[:, 5:])\n",
    "\n",
    "    if(search_type==\"Absolute\"):\n",
    "        title1 = \"Total Occurrences of '{search}'\".format(search=search)\n",
    "        title2 = \"Individual Occurrences of '{search}'\".format(search=search)\n",
    "        title3 = \"Occurrences of '{search}'\".format(search=search)\n",
    "        \n",
    "        # absolute individual data is occurrences per author. total data is sum of occurrences across all authors. bar data is sum of all days per author\n",
    "        individual_data = scale(occurrences[authors_index]) # 2d array- scaled occurrences\n",
    "        total_data = np.sum(scale(occurrences),axis=0) # 1d array- summed across authors\n",
    "        bar_data = np.sum(scale(occurrences[authors_index]),axis=1) # 1d array- summed across days\n",
    "        all_bar_data = np.sum(occurrences[authors_index],axis=1) # 1d array- unscaled\n",
    "\n",
    "    elif(search_type==\"Ratio\"):\n",
    "        title1 = \"Total Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "        title2 = \"Individual Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "        title3 = \"Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "\n",
    "        # individual ratio data is occurrences divided by messages for a given day, per author\n",
    "        messagesums = scale(content_sums[\"Message\"]) # scaled message sums\n",
    "        individual_data = np.where(messagesums[authors_index]!=0, scale(occurrences[authors_index]) / messagesums[authors_index], 0)\n",
    "\n",
    "        # total ratio data is occurrences summed across all authors divided by messages summed across all authors\n",
    "        total_occurrences = np.sum(scale(occurrences),axis=0)\n",
    "        total_messages = np.sum(messagesums,axis=0)\n",
    "        total_data = np.where(total_messages!=0, total_occurrences/total_messages, 0)\n",
    "\n",
    "        # bar data is sum of all occurrences divided by sum of all messages per author\n",
    "        author_occurrences = np.sum(scale(occurrences),axis=1)\n",
    "        author_messages = np.sum(messagesums[authors_index],axis=1)\n",
    "        bar_data = np.where(author_messages!=0, author_occurrences/author_messages, 0)\n",
    "        all_author_occurrences = np.sum(occurrences,axis=1)\n",
    "        all_author_messages = np.sum(messagesums[authors_index],axis=1)\n",
    "        all_bar_data = np.where(all_author_messages!=0, all_author_occurrences/all_author_messages, 0)\n",
    "    \n",
    "    line_ax(ax1, [total_data], [None], False, title1)\n",
    "    line_ax(ax2, individual_data, display_authors, False, title2)\n",
    "\n",
    "    initials = [a[0] for a in display_authors]\n",
    "    bar_ax(ax3, title3, [bar_data], [all_bar_data], initials, search_type==\"Ratio\", [None], [None], False)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    gs.tight_layout(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author sentiment as 2 line plots and a summed bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment():\n",
    "    fig = plt.figure(figsize=(12*figscale,4*figscale))\n",
    "    gs = gridspec.GridSpec(2,7)\n",
    "    ax1 = plt.subplot(gs[0, 0:5])\n",
    "    ax2 = plt.subplot(gs[1, 0:5])\n",
    "    ax3 = plt.subplot(gs[:, 5:])\n",
    "\n",
    "    individual_data = scale(sentiment, average=True)[authors_index]\n",
    "\n",
    "    # total data is total sentiment divided by total number of messages. total sentiment is the daily author sentiment multiplied by daily author messages, summed across all authors. multiplicaiton by author messages happens first, and division by total messages happens last, to ensure different authors are weighted differently during summation, while retaining final -1,1 range of sentiment\n",
    "    total_sentiment = np.sum(sentiment*content_sums[\"Message\"],axis=0) # 1d array of sentiment*messages summed across all authors\n",
    "    total_messages = np.sum(content_sums[\"Message\"],axis=0) # 1d array of messages\n",
    "    total_data = scale(np.where(total_messages!=0, total_sentiment/total_messages, 0), average=True) # 1d array of sentiment/messages\n",
    "\n",
    "    # bar data is daily sentiment multiplied by daily messages, all divided by sum of messages\n",
    "    all_author_messages = np.sum(content_sums[\"Message\"],axis=1) # 1d array of sum of messages across days per author\n",
    "    all_author_sentiment = np.sum(sentiment*content_sums[\"Message\"],axis=1) # 1d array of sum of sentiment*messages\n",
    "    all_bar_data = np.where(all_author_messages!=0, all_author_sentiment/all_author_messages, 0)[authors_index] # 1d array of (sum of sentiment*messages)/messages\n",
    "\n",
    "    author_messages = np.sum(scale(content_sums[\"Message\"]),axis=1) # 1d array of sum of messages across days per author\n",
    "    author_sentiment = np.sum(scale(sentiment*content_sums[\"Message\"]),axis=1) # 1d array of sum of sentiment*messages\n",
    "    bar_data = np.where(author_messages!=0, author_sentiment/author_messages, 0)[authors_index] # 1d array of (sum of sentiment*messages)/messages\n",
    "\n",
    "    line_ax(ax1, [total_data], [None], True, \"Total Sentiment\")\n",
    "    line_ax(ax2, individual_data, display_authors, True, \"Individual Sentiment\")\n",
    "\n",
    "    initials = [a[0] for a in display_authors]\n",
    "    bar_ax(ax3, \"Sentiment\", [bar_data], [all_bar_data], initials, False, [None], [None], True)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    gs.tight_layout(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot most commonly used or most representative words as total and one-per-author list plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_words():\n",
    "    if(word_type==\"Representativeness\"): # do not display total ranking if displaying representativeness\n",
    "        columns = len(display_authors)\n",
    "        title = \"Top {amount} Most Representative Words\".format(amount=display_amount)\n",
    "        total_freqs = []\n",
    "        total_words = []\n",
    "        total_title = []\n",
    "        total_colour = []\n",
    "    else:\n",
    "        total_word_ranking = {} # total ranking is sum of author rankings\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                total_word_ranking[word] = total_word_ranking.get(word,0) + word_ranking[author][word]\n",
    "        total_word_ranking = dict(sorted(total_word_ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "        \n",
    "        columns = len(display_authors)+1\n",
    "        title = \"Top {amount} Most Frequent Words\".format(amount=display_amount)\n",
    "        total_freqs = [list(total_word_ranking.values())[0:display_amount]]\n",
    "        total_words = [list(total_word_ranking.keys())[0:display_amount]]\n",
    "        total_title = [\"Total\"]\n",
    "        total_colour = [colours[\"total\"]]\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=columns, figsize=(12*figscale,0.175*figscale*display_amount+1))\n",
    "\n",
    "    freqs = total_freqs + [list(word_ranking[author].values())[0:display_amount] for author in display_authors]\n",
    "    words = total_words + [list(word_ranking[author].keys())[0:display_amount] for author in display_authors]\n",
    "    words = [[word[0:8]+\"..\" if len(word)>9 else word for word in words[i]] for i in range(len(words))]\n",
    "    titles = total_title + [author for author in display_authors]\n",
    "    word_colours = total_colour + [author_colours[author] for author in display_authors]\n",
    "\n",
    "    for i in range(len(freqs)): # draw a list for total and every author\n",
    "        list_ax(ax[i],words[i],freqs[i],titles[i],word_colours[i])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout(w_pad=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Execution functions</h1>\n",
    "Execute functions to generate statistics, and create a GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>perform calculations to generate all message statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_calculations():\n",
    "    global content_sums\n",
    "    content_sums = calculate_content_sums()\n",
    "    global word_sums\n",
    "    word_sums = calculate_word_sums()\n",
    "    global messages_by_hour\n",
    "    messages_by_hour = get_messages_by_hour()\n",
    "    global occurrences\n",
    "    occurrences = calculate_occurrences()\n",
    "    global sentiment\n",
    "    sentiment = calculate_sentiment()\n",
    "    global word_ranking\n",
    "    word_ranking = calculate_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>draw all plots selected for display</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = {\"Activity Time Series\":plot_activity,\"Average Activity\":plot_average_activity,\"Messages by Hour\":plot_messages_by_hour,\"Search Key Occurrences\":plot_occurrences,\"Sentiment\":plot_sentiment,\"Word Commonality\":plot_words}\n",
    "\n",
    "def draw_plots():\n",
    "    with out:\n",
    "        display_plots = [plots[checkbox.description] for checkbox in plot_checkboxes if checkbox.value==True]\n",
    "        if(len(display_plots)!=0): # draw every selected plot\n",
    "            clear_output(wait=True)\n",
    "            for plot in display_plots:\n",
    "                plot()\n",
    "        else: # clear plots and don't draw anything\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>GUI and execution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(): # set values of variables used for creating plots to repsective widget states\n",
    "    global display_authors\n",
    "    display_authors = [checkbox.description for checkbox in author_checkboxes if checkbox.value==True]\n",
    "    global authors_index\n",
    "    authors_index =[authors.index(author) for author in display_authors]\n",
    "    global display_media\n",
    "    display_media = [checkbox.description for checkbox in media_checkboxes if checkbox.value==True]\n",
    "    global display_content\n",
    "    display_content = [\"Message\" if message_checkbox.value==True else None] + display_media\n",
    "    global timescale\n",
    "    timescale = timescale_buttons.value\n",
    "    global date_range\n",
    "    date_range = date_slider.value\n",
    "    global search, search_type\n",
    "    search = occurrences_box.value\n",
    "    search_type = occurrences_type.value\n",
    "    global word_type, display_amount\n",
    "    word_type = word_type_box.value\n",
    "    display_amount = int(word_display_box.value) if word_display_box.value!=\"\" else 10\n",
    "\n",
    "\n",
    "def apply_clicked(b): # execute plotting upon button click\n",
    "    new_search = True if occurrences_box.value!=search else False # perform a new occurrences calculation if new value input\n",
    "    new_words = True if word_type != word_type_box.value or date_range != date_slider.value else False # perform a new words calculation if different word type or date change\n",
    "    set_values()\n",
    "    if(new_search):\n",
    "        global occurrences\n",
    "        occurrences = calculate_occurrences()\n",
    "    if(new_words):\n",
    "        global word_ranking, total_word_ranking\n",
    "        word_ranking = calculate_words()\n",
    "\n",
    "    draw_plots()\n",
    "\n",
    "apply = Button(description=\"Apply\")\n",
    "apply.on_click(apply_clicked)\n",
    "\n",
    "\n",
    "plot_checkboxes = []\n",
    "for plot in plots.keys():\n",
    "    plot_checkboxes.append(Checkbox(value=False, description=plot, disabled=False, indent=False, layout=Layout(width='200px')))\n",
    "plot_container = VBox([Label(\"Select Analytics\")]+plot_checkboxes)\n",
    "\n",
    "\n",
    "author_checkboxes = []\n",
    "for author in authors:\n",
    "    author_checkboxes.append(Checkbox(value=True, description=author, disabled=False, indent=False, layout=Layout(width='150px')))\n",
    "author_container = VBox([Label(\"Display Authors\")]+author_checkboxes)\n",
    "\n",
    "\n",
    "def change_timescale(change):\n",
    "    global timescale\n",
    "    timescale = timescale_buttons.value\n",
    "\n",
    "    date_slider.min=0\n",
    "    date_slider.max=len(dates[timescale])-1\n",
    "    date_slider.value = (0, len(dates[timescale])-1)\n",
    "    \n",
    "    date_readout.value = slider_readout()\n",
    "\n",
    "timescale_buttons = RadioButtons(options=[\"Days\",\"Weeks\",\"Months\",\"Years\"],layout=Layout(width='150px'))\n",
    "timescale_buttons.observe(change_timescale, names=\"value\")\n",
    "timescale_container = VBox([Label(\"Timescale\"),timescale_buttons])\n",
    "\n",
    "\n",
    "media_checkboxes = []\n",
    "for media in medias.values():\n",
    "    media_checkboxes.append(Checkbox(value=True, description=media, disabled=False, indent=False, layout=Layout(width='150px')))\n",
    "message_checkbox = Checkbox(value=True, description=\"Message\", disabled=False, indent=False, layout=Layout(width='150px'))\n",
    "content_container = VBox([Label(\"Content Types\")]+[message_checkbox]+media_checkboxes)\n",
    "\n",
    "\n",
    "occurrences_box = Text(value='', placeholder=\"Search Key\", layout=Layout(width='150px'))\n",
    "occurrences_type = RadioButtons(options=[\"Absolute\",\"Ratio\"])\n",
    "occurrences_container = VBox([Label(\"Occurrences Settings\")]+[occurrences_box,occurrences_type])\n",
    "\n",
    "word_display_box = Text(value='', placeholder=\"Display Amount\", layout=Layout(width='150px'))\n",
    "word_type_box = RadioButtons(options=[\"Frequency\",\"Representativeness\"])\n",
    "words_container = VBox([Label(\"Word Settings\")]+[word_display_box,word_type_box])\n",
    "\n",
    "settings_container = VBox([occurrences_container,words_container])\n",
    "\n",
    "\n",
    "toolbar = HBox([apply,plot_container,author_container,timescale_container,content_container,settings_container])\n",
    "\n",
    "\n",
    "def slider_readout():\n",
    "    if(timescale==\"Days\" or timescale==\"Weeks\"): # date shown as YY-MM-DD\n",
    "        return str(dates[timescale][date_slider.value[0]]) + \" - \" + str(dates[timescale][date_slider.value[1]])\n",
    "    elif(timescale==\"Months\"):\n",
    "        return str(dates[timescale][date_slider.value[0]])[:-3] + \" - \" + str(dates[timescale][date_slider.value[1]])[:-3]\n",
    "    elif(timescale==\"Years\"):\n",
    "        return str(dates[timescale][date_slider.value[0]])[:-6] + \" - \" + str(dates[timescale][date_slider.value[1]])[:-6]\n",
    "\n",
    "def slider_change(*args):\n",
    "    date_readout.value = slider_readout()\n",
    "\n",
    "date_slider = IntRangeSlider( value=[0, len(dates[\"Days\"])-1], min=0, max=len(dates[\"Days\"])-1, continuous_update=True, readout=False, layout=Layout(width='1030px'))\n",
    "date_slider.observe(slider_change, names='value')\n",
    "date_readout = Label(str(dates[\"Days\"][0]) + \" - \" + str(dates[\"Days\"][-1]))\n",
    "date_range_container = HBox([date_readout,date_slider])\n",
    "\n",
    "\n",
    "out = Output()\n",
    "display(toolbar,date_range_container,out)\n",
    "set_values()\n",
    "perform_calculations()\n",
    "draw_plots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
