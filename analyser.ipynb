{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from ipywidgets import IntRangeSlider, Output, Checkbox, HBox, VBox, RadioButtons, Button, Label, Layout, Text\n",
    "from IPython.display import display, clear_output\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialisation Functions</h1>\n",
    "Read and convert chat data into organised structures. Define properties and helper functions for generating analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_type = \"apple\" # \"apple\" or \"android\"\n",
    "filename = \"chat.txt\"\n",
    "stopwords_file = \"stopwords.txt\"\n",
    "figscale = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>read chat data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = open(filename,\"r\", encoding=\"utf8\").read()\n",
    "if(chat_type==\"apple\"):\n",
    "    lines = chat.split(\"\\n\")[3:]\n",
    "elif(chat_type==\"android\"):\n",
    "    lines = chat.split(\"\\n\")\n",
    "\n",
    "chat_list = []\n",
    "media_list = []\n",
    "\n",
    "for l,line in enumerate(lines):\n",
    "    ascii = line.encode(\"ascii\", errors=\"ignore\").decode() # keep only ascii characters\n",
    "    try: # determine whether line is new chat or continuation of previous chat\n",
    "        if(chat_type==\"apple\"): # first line for apple determined by square brackets surrounding message date\n",
    "            firstline = ascii[0]==\"[\" and ascii[21]==\"]\"\n",
    "        elif(chat_type==\"android\"): #first line for android determined by comma separating date and time, and dash separating time and author\n",
    "            firstline = ascii[10]==\",\" and ascii[18]==\"-\"\n",
    "    except:\n",
    "        firstline = False\n",
    "    \n",
    "    if(firstline):\n",
    "        try: # ignore any broken chats\n",
    "            if(chat_type==\"apple\"):\n",
    "                date = datetime.datetime(int(ascii[7:11]),int(ascii[4:6]),int(ascii[1:3]),int(ascii[13:15]),int(ascii[16:18]),int(ascii[19:21]))\n",
    "                author = ascii[23:ascii.find(\":\",23)]\n",
    "                content = ascii[ascii.find(\":\",23)+2:]\n",
    "            elif(chat_type==\"android\"):\n",
    "                if(ascii.find(\":\",20)==-1): # ignore message if no author\n",
    "                    continue\n",
    "                date = datetime.datetime(int(ascii[6:10]),int(ascii[3:5]),int(ascii[0:2]),int(ascii[12:14]),int(ascii[15:17]))\n",
    "                author = ascii[20:ascii.find(\":\",20)]\n",
    "                content = ascii[ascii.find(\":\",20)+2:]\n",
    "            \n",
    "            if(content==\"image omitted\" or content==\"video omitted\" or content==\"sticker omitted\" or content==\"audio omitted\" or content==\"GIF omitted\" or content==\"<Media omitted>\"):\n",
    "                media_list.append({\"date\":date,\"auth\":author,\"cont\":content})\n",
    "            else:\n",
    "                chat_list.append({\"date\":date,\"auth\":author,\"cont\":content})\n",
    "        except:\n",
    "            pass\n",
    "    else: # if line is continuation of previous chat, append content to its entry\n",
    "        chat_list[-1][\"cont\"] += (\" \"+ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>separate chat data by author</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_chats = {}\n",
    "for chat in chat_list:\n",
    "    author_chats.setdefault(chat[\"auth\"], []).append(chat)\n",
    "\n",
    "author_media = {}\n",
    "for media in media_list:\n",
    "    author_media.setdefault(media[\"auth\"], []).append(media)\n",
    "\n",
    "for author in author_chats.keys(): # fill any gaps in dictionaries for authors which have either only sent chats or only sent media\n",
    "    if(author not in author_media.keys()):\n",
    "        author_media[author] = []\n",
    "for author in author_media.keys():\n",
    "    if(author not in author_chats.keys()):\n",
    "        author_chats[author] = []\n",
    "\n",
    "authors = list(author_chats.keys())\n",
    "if(chat_type==\"apple\"):\n",
    "    medias = {\"image omitted\":\"Image\",\n",
    "               \"video omitted\":\"Video\",\n",
    "               \"sticker omitted\":\"Sticker\",\n",
    "               \"audio omitted\":\"Audio\",\n",
    "               \"GIF omitted\":\"GIF\",}\n",
    "elif(chat_type==\"android\"): # android chat does not differentiate between media types\n",
    "    medias = {\"media omitted\":\"Media\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>define colours for plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = {\"total\":\"slategrey\",\n",
    "           \"messages_per_day\":\"tab:blue\",\n",
    "           \"words_per_message\":\"tab:purple\",\n",
    "           \"Image\":\"dodgerblue\",\n",
    "           \"Video\":\"darkslateblue\",\n",
    "           \"Sticker\":\"palevioletred\",\n",
    "           \"Audio\":\"mediumseagreen\",\n",
    "           \"GIF\":\"goldenrod\",\n",
    "           \"Media\":\"goldenrod\",\n",
    "           \"occurrences\":\"tab:red\",\n",
    "           \"alltime_lines\":\"indianred\",\n",
    "           \"major_grid\":\"gainsboro\",\n",
    "           \"minor_grid\":\"whitesmoke\",\n",
    "           \"year_grid\":\"silver\",\n",
    "           None:\"tab:blue\"}\n",
    "\n",
    "author_colours = {} # generate distinct colours for each author\n",
    "for a,author in enumerate(authors):\n",
    "    author_colours[author] = cm.get_cmap(\"tab10\")(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create dates for all timescales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = (chat_list[-1][\"date\"].date() - chat_list[0][\"date\"].date()).days + 1\n",
    "day_dates = [chat_list[0][\"date\"].date() + datetime.timedelta(days=i) for i in range(total_days)]\n",
    "\n",
    "for d,date in enumerate(day_dates): # find position of first monday in dates list\n",
    "    if(date.weekday()==0):\n",
    "        first_monday=d\n",
    "        break\n",
    "week_dates = [day_dates[first_monday] + datetime.timedelta(days=i) for i in range(0,total_days,7)] # week dates are the first day, then every subsequent monday\n",
    "if(first_monday!=0):\n",
    "    week_dates = [day_dates[0]] + week_dates\n",
    "total_weeks = len(week_dates)\n",
    "\n",
    "total_months = (chat_list[-1][\"date\"].year - chat_list[0][\"date\"].year) * 12 + chat_list[-1][\"date\"].month - chat_list[0][\"date\"].month + 1\n",
    "month_dates = [chat_list[0][\"date\"].date()] + [datetime.date(chat_list[0][\"date\"].year,chat_list[0][\"date\"].month,1) + relativedelta(months=i) for i in range(1,total_months)]\n",
    "\n",
    "total_years = chat_list[-1][\"date\"].year - chat_list[0][\"date\"].year + 1\n",
    "year_dates = [chat_list[0][\"date\"].date()] + [datetime.date(chat_list[0][\"date\"].year,1,1) + relativedelta(years=i) for i in range(1,total_years)]\n",
    "\n",
    "dates = {\"Days\":day_dates,\"Weeks\":week_dates,\"Months\":month_dates,\"Years\":year_dates}\n",
    "first_date = chat_list[0][\"date\"].date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>convert data to appropriate timescale and trim to date range</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_index(i): # calculates index of new timescale relative to index of day timescale\n",
    "    if(timescale==\"Weeks\"):\n",
    "        return math.floor(((datetime.timedelta(days=i)).days + 7-first_monday)/7) # week is calculated as 7 days from monday to monday\n",
    "    elif(timescale==\"Months\"):\n",
    "        return ((first_date + datetime.timedelta(days=i)).year - first_date.year) * 12 + (first_date + datetime.timedelta(days=i)).month - first_date.month # month is calculated as (year difference)*12 + (month difference)\n",
    "    elif(timescale==\"Years\"):\n",
    "        return (first_date + datetime.timedelta(days=i)).year - first_date.year\n",
    "\n",
    "def scale(data, average=False, author=None): # convert day sums to sums of any other timescale\n",
    "    if(timescale==\"Days\"): # don't convert if already days\n",
    "        return data[date_range[0]:date_range[1]+1]\n",
    "    \n",
    "    if(isinstance(data[0], list)): # creates a new list object in the same shape as the old one but condensed in time- either list or list of lists\n",
    "        new_timescale = [[0]*len(data[0]) for _ in range(len(dates[timescale]))]\n",
    "    else:\n",
    "        new_timescale = [0]*len(dates[timescale])\n",
    "\n",
    "    if(average): # average scaling is the average of all data values belonging to new timescale weighted by content sums of the given day\n",
    "        if(author==None): # daily message sums of total of all authors\n",
    "            sums = [sum(day) for day in zip(*[content_sums[author][\"Message\"] for author in authors])]\n",
    "        else: # daily message sums for given author\n",
    "            sums = content_sums[author][\"Message\"]\n",
    "        new_timescale_sums = [0]*len(dates[timescale]) # sums also become scaled to new timescale\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            new_timescale[calculate_index(i)] += data[i] * sums[i]\n",
    "            new_timescale_sums[calculate_index(i)] += sums[i]\n",
    "        \n",
    "        new_timescale = [timeperiod[0]/timeperiod[1] if timeperiod[1]!=0 else 0 for timeperiod in zip(new_timescale,new_timescale_sums)] # divide each timeperiod of new timescale by the sums of messages of given timeperiod\n",
    "\n",
    "    else: # non-average scaling is the sum of all data values belonging to new timescale\n",
    "        for i in range(len(data)):\n",
    "            if(isinstance(data[i], list)): # element-wise sum of all day lists belonging to new timescale (individual sum of 12AMs, 1AMs etc of all days)\n",
    "                new_timescale[calculate_index(i)] = [x[0]+x[1] for x in zip(new_timescale[calculate_index(i)], data[i])]\n",
    "            else: # sum all days belonging to new timescale\n",
    "                new_timescale[calculate_index(i)] += data[i]\n",
    "    \n",
    "    return new_timescale[date_range[0]:date_range[1]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calculation functions</h1>\n",
    "Convert per-author chat data into a per-author daily representation of a statistic. Later used by plot functions to turn into finalised statistics ready for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of all separate content types</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_content_sums():\n",
    "    content_sums = {} # list of sums of content for a given timescale, for all authors\n",
    "    for author in author_chats:\n",
    "        if(chat_type==\"apple\"): # individual list of sums for every message type\n",
    "            sums = {media:[0]*len(dates[\"Days\"]) for media in [\"Message\",\"Image\",\"Video\",\"Sticker\",\"Audio\",\"GIF\"]}\n",
    "        else:\n",
    "            sums = {media:[0]*len(dates[\"Days\"]) for media in [\"Message\",\"Media\"]}\n",
    "        \n",
    "        for message in author_chats[author]: # sum messages\n",
    "            sums[\"Message\"][(message[\"date\"].date() - dates[\"Days\"][0]).days] += 1\n",
    "        \n",
    "        for media in author_media[author]: # sum media\n",
    "            sums[medias[media[\"cont\"]]][(media[\"date\"].date() - dates[\"Days\"][0]).days] += 1\n",
    "        \n",
    "        content_sums[author] = sums\n",
    "\n",
    "    return content_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of words in messages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_sums():\n",
    "    word_sums = {} # daily sums of words for every author\n",
    "    for author in author_chats:\n",
    "        sums = [0]*len(dates[\"Days\"])\n",
    "        for message in author_chats[author]:\n",
    "            sums[(message[\"date\"].date() - dates[\"Days\"][0]).days] += len(message[\"cont\"].split(\" \")) # adds number of words in message to daily sum\n",
    "        word_sums[author] = sums\n",
    "    return word_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sums of messages sent for every hour</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_by_hour():\n",
    "    messages_by_hour = {} # daily messages by hour for each author\n",
    "    for author in author_chats:\n",
    "        sums = [[0]*24 for i in range(len(dates[\"Days\"]))] # 24 hour list for each day\n",
    "        for message in author_chats[author]:\n",
    "            sums[(message[\"date\"].date() - dates[\"Days\"][0]).days][message[\"date\"].hour] += 1\n",
    "        messages_by_hour[author] = sums\n",
    "    \n",
    "    return messages_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily occurrences of a given search key</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occurrences():\n",
    "    global search\n",
    "    search = re.sub(r'[^a-zA-Z0-9\\s]', '', search.lower()) # search key is alphanumeric lowercase\n",
    "    occurrences = {} # occurrences for each day for each author\n",
    "\n",
    "    for author in author_chats:\n",
    "        sums = [0]*len(dates[\"Days\"])\n",
    "        for message in author_chats[author]:\n",
    "            message_alphanum = re.sub(r'[^a-zA-Z0-9\\s]', '', message[\"cont\"].lower()) # message is alphanumeric lowercase\n",
    "            sums[(message[\"date\"].date() - dates[\"Days\"][0]).days] += message_alphanum.count(search) # add occurrences of the search key\n",
    "        occurrences[author] = sums\n",
    "    \n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate daily sentiment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment():\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment = {}\n",
    "\n",
    "    for author in author_chats:\n",
    "        sums = [0]*len(dates[\"Days\"])\n",
    "        weights = [0]*len(dates[\"Days\"])\n",
    "        for message in author_chats[author]:\n",
    "            weight = len(re.split('[-.,:;!? ]', message[\"cont\"]))**0.5 # longer message receives an amplified sentiment score, with diminishing returns\n",
    "            score = sid.polarity_scores(message[\"cont\"])[\"compound\"] * weight # calculate sentiment of message- weighted\n",
    "            sums[(message[\"date\"].date() - dates[\"Days\"][0]).days] += score\n",
    "            weights[(message[\"date\"].date() - dates[\"Days\"][0]).days] += weight\n",
    "\n",
    "        sentiment[author] = [sums[i]/weights[i] if weights[i]!=0 else 0 for i in range(len(sums))] # divide each day of sentiment by day sum of weights to bring back to range of -1,1\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>calculate most commonly used or most representative words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_words():\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set([re.sub(r'[^a-zA-Z0-9\\s]', '', word) for word in open(stopwords_file, \"r\").read().split(\"\\n\")]) # filters common \"meaningless\" words\n",
    "    lemma_exceptions = {\"cos\",\"cus\"} # words which are exempt from lemmatisation\n",
    "\n",
    "\n",
    "    word_ranking = {} # ranking of words for each author. either frequency or representativeness\n",
    "    for author in author_chats:\n",
    "        ranking = {}\n",
    "        for message in author_chats[author]:\n",
    "            if(message[\"date\"].date()>=dates[timescale][date_range[0]] and message[\"date\"].date()<=dates[timescale][date_range[1]]):\n",
    "                added_lemmas = {} # dictionary storing how many of which lemmas have been added in the current message. used for scaling down the value of subsequent lemmas\n",
    "                words = re.split('[-.,:;!? ]', message[\"cont\"]) # split message into words by any punctuation\n",
    "                for word in words:\n",
    "                    word_alphanum = re.sub(r'[^a-zA-Z0-9\\s]', '', word.lower()) # convert word to only contain lowercase letters and numbers and spaces\n",
    "                    if(word_alphanum != \"\" and word_alphanum not in stop_words):\n",
    "                        if(word_alphanum not in lemma_exceptions):\n",
    "                            lemma = lemmatizer.lemmatize(word_alphanum)\n",
    "                        else:\n",
    "                            lemma = word_alphanum\n",
    "                        \n",
    "                        if(word_type==\"Representativeness\"): # if representativeness calculation, subsequent lemmas within the same message are scaled down in value\n",
    "                            added_lemmas[lemma] = added_lemmas.get(lemma,0) + 1\n",
    "                            scaled = added_lemmas[lemma]**-0.5\n",
    "                            ranking[lemma] = ranking.get(lemma,0) + scaled\n",
    "                        else: # if frequency calculation, every lemma is worth the same\n",
    "                            ranking[lemma] = ranking.get(lemma,0) + 1\n",
    "        \n",
    "        word_ranking[author] = dict(sorted(ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "\n",
    "    if(word_type==\"Representativeness\"):\n",
    "        total_word_ranking = {} # total ranking is sum of author rankings\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                total_word_ranking[word] = total_word_ranking.get(word,0) + word_ranking[author][word]\n",
    "        total_word_ranking = dict(sorted(total_word_ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                word_ranking[author][word] = math.log(word_ranking[author][word]) * (word_ranking[author][word]/total_word_ranking[word]) # author word usage over total usage scaled by log of author usage\n",
    "            \n",
    "            word_ranking[author] = dict(sorted(word_ranking[author].items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "            max_value = list(word_ranking[author].values())[0]\n",
    "            word_ranking[author] = {k: v / max_value for k, v in word_ranking[author].items()}\n",
    "\n",
    "    return word_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot helper functions</h1>\n",
    "Implement generic plot types (line plot, bar plot etc.) which visualise input data. Called by plot functions to create individual consitiuent axes of a full visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>line plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_ax(ax, data, labels, bipolar, title):\n",
    "    date_axis = dates[timescale][date_range[0]:date_range[1]+1]\n",
    "\n",
    "    if(len(date_axis)>50): # display point markers if little enough data\n",
    "        marker=\"none\"\n",
    "    else:\n",
    "        marker=\".\"\n",
    "\n",
    "    max_val = max([max([abs(point) for point in line]) for line in data]) if max([max([abs(point) for point in line]) for line in data])!=0 else 1 # maximum value in all data for axis limits\n",
    "    \n",
    "    for l,line in enumerate(data):\n",
    "        if(labels==[None]): # line colour, either total colour or author colour\n",
    "            colour = colours[\"total\"]\n",
    "        else:\n",
    "            colour = author_colours[labels[l]]\n",
    "        \n",
    "        ax.plot(date_axis, line, color=colour, label=labels[l], marker=marker, linewidth=1, zorder=3) # plot data\n",
    "        if(len(data)==1): # fill underneath line if one data point\n",
    "            ax.fill_between(date_axis, line, alpha=0.1, color=colour)\n",
    "\n",
    "    if(labels!=[None]): # plot legend if labels present\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.125), fontsize=8, ncol=100)\n",
    "    \n",
    "    ax.title.set_text(title)\n",
    "    if(not bipolar):\n",
    "        ax.set_ylim([0, max_val*1.05])\n",
    "    else:\n",
    "        ax.axhline(y=0, linewidth=0.5, color=\"black\", zorder=3)\n",
    "        ax.set_ylim([-max_val*1.05, max_val*1.05])\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "    ax.grid(True,zorder=0,color=colours[\"major_grid\"],linewidth = 1)\n",
    "    ax.grid(True, zorder=0,color=colours[\"minor_grid\"], which='minor')\n",
    "    ax.xaxis.grid(which='minor', visible=False)\n",
    "    for year in dates[\"Years\"]: # year grids\n",
    "        ax.axvline(x=year, color=colours[\"year_grid\"], zorder=2, linewidth=1)\n",
    "    if(date_range[0]!=date_range[1]):\n",
    "        ax.set_xlim([min(date_axis), max(date_axis)]) # set x axis to date limits (if more than 1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeltext(value,ratio): # generate the label text\n",
    "    prefix=\"\"\n",
    "    if(ratio): \n",
    "        prefix=\"1:\"\n",
    "        if(value!=0):\n",
    "            value=1/value\n",
    "        else:\n",
    "            return prefix+\"âˆž\"\n",
    "    return prefix+str(f'{float(f\"{value:.3g}\"):g}')\n",
    "\n",
    "def addlabels(ax,data,alltime_data,ratio,date): # adds a label for the value rounded to 3 significant figures\n",
    "    width = 0.9 / len(data)\n",
    "    shift = np.linspace(width*(len(data)-1)/2, -width*(len(data)-1)/2, len(data)) # calculate y offset for multiple bars\n",
    "\n",
    "    for bs, bars in enumerate(data): # iterate through every collection of bars (for multi-bar plots)\n",
    "        for b, bar in enumerate(bars): # iterate through every bar\n",
    "            if(max(max(data))!=0):\n",
    "                if(bar/max(max(data))>0.2): # label inside of bar if enough space\n",
    "                    colour=\"white\"\n",
    "                    align=\"right\"\n",
    "                else: # label outside of bar if not enough space\n",
    "                    colour=\"black\"\n",
    "                    align=\"left\"\n",
    "            else:\n",
    "                colour=\"black\"\n",
    "                align=\"left\"\n",
    "            \n",
    "            if(date_range!=(0,len(dates[timescale])-1) and date==True): # write fraction of all-time value if subsection of date selected\n",
    "                label = labeltext(bar,ratio)+\" / \"+labeltext(alltime_data[bs][b],ratio)\n",
    "            else:\n",
    "                label = labeltext(bar,ratio)\n",
    "            \n",
    "            ax.text(bar, b+shift[bs]-0.025, label, va=\"center\", ha=align, color=colour, fontsize=7)\n",
    "\n",
    "def bar_ax(ax, title, data, alltime_data, authors, ratio, colour_ids, labels, bipolar):\n",
    "    ax.title.set_text(title)\n",
    "    if(len(data)!=0):\n",
    "        y = np.arange(len(authors)) # y axis is number of authors\n",
    "        width = 0.9 / len(data)\n",
    "        shift = np.linspace(width*(len(data)-1)/2, -width*(len(data)-1)/2, len(data)) # calculate y offset for multiple bars\n",
    "\n",
    "        bar_charts = []\n",
    "        \n",
    "        for i,item in enumerate(data): # plot all bars\n",
    "            bar_charts.append(ax.barh(y+shift[i], item, width, color=colours[colour_ids[i]], label=labels[i], zorder=2))\n",
    "        \n",
    "        if(colour_ids==[None]): # if colours not provided, sets each individual bar to author colour (guaranteed only one bar per author)\n",
    "            colour_ids = [author_colours[a] for a in display_authors]\n",
    "            for i in range(len(bar_charts[0])):\n",
    "                bar_charts[0][i].set_color(colour_ids[i])\n",
    "        \n",
    "        if(date_range!=(0,len(dates[timescale])-1)): # draw all-time lines if subsection of date selected\n",
    "            for bs, bars in enumerate(bar_charts):\n",
    "                for b, bar in enumerate(bars):\n",
    "                    ax.vlines(alltime_data[bs][b],ymin=bar.get_y(),ymax=bar.get_y() + bar.get_height(),colors='white',linewidth=0.5,path_effects=[pe.Stroke(linewidth=2, foreground=colours[\"alltime_lines\"]), pe.Normal()])\n",
    "        \n",
    "        max_val = max([max([abs(point) for point in bar]) for bar in data+alltime_data]) if max([max([abs(point) for point in bar]) for bar in data+alltime_data])!=0 else 1 # maximum value in all data and alltime data combined for axis limit\n",
    "        ax.set_xlim(0,max_val*1.05)\n",
    "\n",
    "        if(bipolar): # set axis limit to maximum on both sides, centred at 0\n",
    "            ax.set_xlim(-max_val*1.05,max_val*1.05)\n",
    "            ax.axvline(x=0, linewidth=0.5, color=\"black\")\n",
    "        \n",
    "        ax.xaxis.grid(color=colours[\"major_grid\"])\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(authors)\n",
    "        ax.set_yticks(np.arange(-0.5, len(authors), 1), minor=True)\n",
    "        ax.tick_params(axis='y', which='minor', length=0)\n",
    "        ax.grid(which='minor', color=colours[\"major_grid\"], zorder=0)\n",
    "        if(None not in labels):\n",
    "            ax.legend(fontsize=8)\n",
    "        \n",
    "        addlabels(ax, data, alltime_data, ratio, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>polar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polar(fig, data, labels, clock, total):\n",
    "    if(clock==\"pm\"):\n",
    "        size = [1.2, 0, 1, 1] # plot size\n",
    "        tick_labels = range(12,24) # tick labels\n",
    "        ring = -3 # inner ring size\n",
    "    else:\n",
    "        size = [1.4, 0.2, 0.6, 0.6] # plot size\n",
    "        tick_labels = range(0,12) # tick labels\n",
    "        ring = -1.4 # inner ring size\n",
    "    if(not total): # total and individual rings are placed side-by-side\n",
    "        size[0]+=1.2\n",
    "\n",
    "    ax = fig.add_axes(size, polar=True) # place inner plot of size dependent on whether inner am or outer pm\n",
    "\n",
    "    ax.set_rorigin(ring) # inner ring size\n",
    "    ax.set_yticks([]) # hide grid - added manually to be polygonal\n",
    "    ax.set_ylim([0,1]) # plots values of range 0-1\n",
    "    ax.set_xticks(np.linspace(0, 2*np.pi, 12, endpoint=False)) # 12 ticks\n",
    "    ax.set_xticklabels(tick_labels) # tick labels\n",
    "    ax.tick_params(pad=-2.5) # label distance from ticks\n",
    "    ax.set_theta_direction(-1) # clockwise\n",
    "    ax.set_theta_offset(np.pi/2.0) # start from top\n",
    "    ax.spines['polar'].set_visible(False) # hide outer border - added manually to be polygonal\n",
    "    \n",
    "    theta = np.linspace(0, 2*np.pi, 13) # plot new polygonal gridlines with 5 segments\n",
    "    for i in range(0,6):\n",
    "        if(i==0 or i==5):\n",
    "            ax.plot(theta, [i/5]*13, color='black', linewidth=1)\n",
    "        else:\n",
    "            ax.plot(theta, [i/5]*13, color=colours[\"major_grid\"], linewidth=0.5)\n",
    "    ax.axvline(x = 0, color='black') # axis break at 12pm/am\n",
    "\n",
    "    for i,item in enumerate(data): # plot lines\n",
    "        if(total): # line colour\n",
    "            colour = colours[\"total\"]\n",
    "        else:\n",
    "            colour = author_colours[labels[i]]\n",
    "\n",
    "        if(clock==\"pm\"):\n",
    "            hours = item[12:24] + [item[0]] # 12pm-12am if pm\n",
    "        else:\n",
    "            hours = item[0:13] # 12am-12pm if am\n",
    "        ax.plot(theta, hours, marker='.', markevery=range(0,12), color=colour, label=labels[i], linewidth=1)\n",
    "        if(len(data)==1):\n",
    "            ax.fill(theta, hours, alpha=0.1, color=colour)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>list plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_ax(ax,words,freqs,title,word_colour):\n",
    "    ax.barh(words,freqs,color=word_colour) # plot\n",
    "    ax.title.set_text(title)\n",
    "    ax.invert_yaxis() # top to bottom\n",
    "    ax.set_ylim([display_amount,-1]) # prevent axis padding\n",
    "    ax.tick_params(axis='y', which='minor', length=0)\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    addlabels(ax,[freqs],None,False,False)\n",
    "    if(len(words)==0): # hide tick labels if no words\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_yticks(np.arange(-0.5, display_amount, 1), minor=True)\n",
    "    ax.grid(which='minor', color=colours[\"major_grid\"], zorder=0)\n",
    "    for j in range(display_amount): # word ranking label\n",
    "        ax.text(ax.get_xlim()[1],j,j+1, va=\"center\", ha=\"right\", color=colours[\"year_grid\"], fontsize=7, zorder=0)\n",
    "    for j in range(display_amount,0,-10): # separator for every 10 words\n",
    "        ax.axhline(y=j-1.5, color=colours[\"year_grid\"], zorder=2, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot functions</h1>\n",
    "Initialise plot objects, convert daily representation of statistic into finalised statistic, and call plot helper functions to fill axes and create a full visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author sums of content as 2 line plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_content():\n",
    "    fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(12*figscale,4*figscale))\n",
    "\n",
    "    # individual data is one list of all content types summed together per author. total data is the sum of all authors.\n",
    "    individual_data = [[sum(day) for day in zip(*[scale(content_sums[author][message_type]) for message_type in display_content])] for author in display_authors]\n",
    "    all_authors =     [[sum(day) for day in zip(*[content_sums[author][message_type] for message_type in display_content])] for author in authors]\n",
    "    total_data =      scale([sum(day) for day in zip(*all_authors)])\n",
    "    \n",
    "    line_ax(ax[0], [total_data], [None], False, \"Total Content\")\n",
    "    line_ax(ax[1], individual_data, display_authors, False, \"Individual Content\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot messages per day, words per message, and media to message ratio as 3 bar plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_content():\n",
    "    # calculate daily sums of messages and words, per author, as a list\n",
    "    messagesums = [sums[\"Message\"] for author,sums in content_sums.items() if author in display_authors]\n",
    "    wordsums    = [sums for author,sums in word_sums.items() if author in display_authors]\n",
    "    mediasums   = [[sums[media] for media in display_media] for author,sums in content_sums.items() if author in display_authors]\n",
    "    num_days    = (dates[timescale][date_range[1]]-dates[timescale][date_range[0]]).days+1\n",
    "\n",
    "    # messages per day is the sum of all messages divided by number of days, per author\n",
    "    messages_per_day         = [sum(author)/num_days for author in [scale(sum) for sum in messagesums]]\n",
    "    alltime_messages_per_day = [sum(author)/total_days for author in messagesums]\n",
    "\n",
    "    # words per message is the sum of all words divided by the sum of all messages, per author\n",
    "    words_per_message         = [sum(author[1])/sum(author[0]) for author in zip([scale(sum) for sum in messagesums],[scale(sum) for sum in wordsums])]\n",
    "    alltime_words_per_message = [sum(author[1])/sum(author[0]) for author in zip(messagesums,wordsums)]\n",
    "\n",
    "    # message to media ratio is the sum of media types divided by the sum of all messages, per media, per author\n",
    "    media_to_message = [[0]*len(display_authors) for i in range(len(display_media))]\n",
    "    for i in range(len(display_media)):\n",
    "        for j in range(len(display_authors)):\n",
    "            media_to_message[i][j] = sum([scale(sum) for sum in mediasums[j]][i])/sum([scale(sum) for sum in messagesums][j])\n",
    "    alltime_media_to_message = [[0]*len(display_authors) for i in range(len(display_media))]\n",
    "    for i in range(len(display_media)):\n",
    "        for j in range(len(display_authors)):\n",
    "            alltime_media_to_message[i][j] = sum(mediasums[j][i])/sum(messagesums[j])\n",
    "\n",
    "    initials = [a[0] for a in display_authors] # all charts after first display only first letter of author\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12*figscale,4*figscale))\n",
    "\n",
    "    bar_ax(ax[0], \"Average Daily Messages\",    [messages_per_day],  [alltime_messages_per_day],  display_authors,  False, [\"messages_per_day\"],  [None],        False)\n",
    "    bar_ax(ax[1], \"Average Words per Message\", [words_per_message], [alltime_words_per_message], initials,         False, [\"words_per_message\"], [None],        False)\n",
    "    bar_ax(ax[2], \"Media to Message Ratio\",    media_to_message,    alltime_media_to_message,    initials,         True,  display_media,         display_media, False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author messages by hour as 2 sets of AM-PM polar plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_messages_by_hour():\n",
    "    fig = plt.figure(figsize=(4*figscale, 4*figscale))\n",
    "\n",
    "    # individual data is one list of sums of all hourly sums, normalised so highest value is 1, per author\n",
    "    individual_data = [[sum(day) for day in zip(*scale(messages_by_hour[author]))] for author in display_authors]\n",
    "    individual_data_normalised = [[element/max(author) if max(author)!=0 else 0 for element in author] for author in individual_data]\n",
    "\n",
    "    # toatl data is one list of sums of all hourly sums, summed across all authors, normalised so highest value is 1\n",
    "    all_authors = [[sum(day) for day in zip(*scale(messages_by_hour[author]))] for author in authors]\n",
    "    total_data = [sum(author) for author in zip(*all_authors)]\n",
    "    total_data_normalised = [element/max(total_data) if max(total_data)!=0 else 0 for element in total_data]\n",
    "\n",
    "    ax = plot_polar(fig,[total_data_normalised],[None],\"pm\",True)\n",
    "    ax.set_title(\"Total Messages by Hour\")\n",
    "    plot_polar(fig,[total_data_normalised],[None],\"am\",True)\n",
    "\n",
    "    ax = plot_polar(fig,individual_data_normalised,display_authors,\"pm\",False)\n",
    "    ax.set_title(\"Individual Messages by Hour\")\n",
    "    ax.legend(loc='center right', bbox_to_anchor=(1.425, 0.5), fontsize=8)\n",
    "    plot_polar(fig,individual_data_normalised,display_authors,\"am\",False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author occurrences of a given search key as 2 line plots and a summed bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occurrences():\n",
    "    fig = plt.figure(figsize=(12*figscale,4*figscale))\n",
    "    gs = gridspec.GridSpec(2,7)\n",
    "    ax1 = plt.subplot(gs[0, 0:5])\n",
    "    ax2 = plt.subplot(gs[1, 0:5])\n",
    "    ax3 = plt.subplot(gs[:, 5:])\n",
    "\n",
    "    if(search_type==\"Absolute\"):\n",
    "        title1 = \"Total Occurrences of '{search}'\".format(search=search)\n",
    "        title2 = \"Individual Occurrences of '{search}'\".format(search=search)\n",
    "        title3 = \"Occurrences of '{search}'\".format(search=search)\n",
    "        \n",
    "        # absolute individual data is occurrences per author. total data is sum of occurrences across all authors. bar data is sum of all days per author\n",
    "        individual_data =  [scale(occurrences[author]) for author in display_authors]\n",
    "        total_data =       [sum(author) for author in zip(*individual_data)]\n",
    "        bar_data =         [sum(scale(occurrences[author])) for author in display_authors]\n",
    "        alltime_bar_data = [sum(occurrences[author]) for author in display_authors]\n",
    "\n",
    "    elif(search_type==\"Ratio\"):\n",
    "        title1 = \"Total Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "        title2 = \"Individual Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "        title3 = \"Occurrences of '{search}' to Message Ratio\".format(search=search)\n",
    "\n",
    "        # individual ratio data is occurrences divided by messages for a given day, per author\n",
    "        individual_data = [[day[0]/day[1] if day[1]!=0 else 0 for day in zip(scale(occurrences[author]),scale(content_sums[author][\"Message\"]))] for author in display_authors]\n",
    "\n",
    "        # total ratio data is occurrences summed across all authors divided by messages summed across all authors\n",
    "        total_occurrences = [sum(day) for day in zip(*[occurrences[author] for author in authors])]\n",
    "        total_messages =    [sum(day) for day in zip(*[content_sums[author][\"Message\"] for author in authors])]\n",
    "        total_data =        [day[0]/day[1] if day[1]!=0 else 0 for day in zip(scale(total_occurrences),scale(total_messages))]\n",
    "\n",
    "        # bar data is sum of all occurrences divided by sum of all messages per author\n",
    "        bar_data =         [sum(scale(occurrences[author]))/sum(scale(content_sums[author][\"Message\"])) for author in display_authors]\n",
    "        alltime_bar_data = [sum(occurrences[author])/sum(content_sums[author][\"Message\"]) for author in display_authors]\n",
    "    \n",
    "    line_ax(ax1, [total_data], [None], False, title1)\n",
    "    line_ax(ax2, individual_data, display_authors, False, title2)\n",
    "\n",
    "    initials = [a[0] for a in display_authors]\n",
    "    bar_ax(ax3, title3, [bar_data], [alltime_bar_data], initials, search_type==\"Ratio\", [None], [None], False)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    gs.tight_layout(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot total and per-author sentiment as 2 line plots and a summed bar plot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment():\n",
    "    fig = plt.figure(figsize=(12*figscale,4*figscale))\n",
    "    gs = gridspec.GridSpec(2,7)\n",
    "    ax1 = plt.subplot(gs[0, 0:5])\n",
    "    ax2 = plt.subplot(gs[1, 0:5])\n",
    "    ax3 = plt.subplot(gs[:, 5:])\n",
    "\n",
    "    individual_data = [scale(sentiment[author], average=True, author=author) for author in display_authors]\n",
    "\n",
    "    # total data is total sentiment divided by total number of messages. total sentiment is the daily author sentiment multiplied by daily author messages, summed across all authors. multiplicaiton by author messages happens first, and division by total messages happens last, to ensure different authors are weighted differently during summation, while retaining final -1,1 range of sentiment\n",
    "    total_sentiment = [sum(author) for author in zip(*[[day[0]*day[1] for day in zip(sentiment[author],content_sums[author][\"Message\"])] for author in authors])]\n",
    "    total_messages = [sum(day) for day in zip(*[content_sums[author][\"Message\"] for author in authors])]\n",
    "    total_data = scale([day[0]/day[1] if day[1]!=0 else 0 for day in zip(total_sentiment,total_messages)], average=True)\n",
    "\n",
    "    # bar data is daily sentiment multiplied by daily messages, all divided by sum of messages\n",
    "    alltime_bar_data = [sum([day[0]*day[1] for day in zip(sentiment[author],content_sums[author][\"Message\"])])/sum(content_sums[author][\"Message\"]) for author in display_authors]\n",
    "    bar_data =         [sum([day[0]*day[1] for day in zip(scale(sentiment[author], average=True),scale(content_sums[author][\"Message\"]))])/sum(scale(content_sums[author][\"Message\"])) for author in display_authors]\n",
    "\n",
    "    line_ax(ax1, [total_data], [None], True, \"Total Sentiment\")\n",
    "    line_ax(ax2, individual_data, display_authors, True, \"Individual Sentiment\")\n",
    "\n",
    "    initials = [a[0] for a in display_authors]\n",
    "    bar_ax(ax3, \"Sentiment\", [bar_data], [alltime_bar_data], initials, False, [None], [None], True)\n",
    "\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    gs.tight_layout(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>plot most commonly used or most representative words as total and one-per-author list plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_words():\n",
    "    if(word_type==\"Representativeness\"): # do not display total ranking if displaying representativeness\n",
    "        columns = len(display_authors)\n",
    "        title = \"Top {amount} Most Representative Words\".format(amount=display_amount)\n",
    "        total_freqs = []\n",
    "        total_words = []\n",
    "        total_title = []\n",
    "        total_colour = []\n",
    "    else:\n",
    "        total_word_ranking = {} # total ranking is sum of author rankings\n",
    "        for author in word_ranking:\n",
    "            for word in word_ranking[author]:\n",
    "                total_word_ranking[word] = total_word_ranking.get(word,0) + word_ranking[author][word]\n",
    "        total_word_ranking = dict(sorted(total_word_ranking.items(), key=lambda item: item[1], reverse=True)) # sorts dictionary by highest ranking\n",
    "        \n",
    "        columns = len(display_authors)+1\n",
    "        title = \"Top {amount} Most Frequent Words\".format(amount=display_amount)\n",
    "        total_freqs = [list(total_word_ranking.values())[0:display_amount]]\n",
    "        total_words = [list(total_word_ranking.keys())[0:display_amount]]\n",
    "        total_title = [\"Total\"]\n",
    "        total_colour = [colours[\"total\"]]\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=columns, figsize=(12*figscale,0.175*figscale*display_amount+1))\n",
    "\n",
    "    freqs = total_freqs + [list(word_ranking[author].values())[0:display_amount] for author in display_authors]\n",
    "    words = total_words + [list(word_ranking[author].keys())[0:display_amount] for author in display_authors]\n",
    "    words = [[word[0:8]+\"..\" if len(word)>9 else word for word in words[i]] for i in range(len(words))]\n",
    "    titles = total_title + [author for author in display_authors]\n",
    "    word_colours = total_colour + [author_colours[author] for author in display_authors]\n",
    "\n",
    "    for i in range(len(freqs)): # draw a list for total and every author\n",
    "        list_ax(ax[i],words[i],freqs[i],titles[i],word_colours[i])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout(w_pad=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Execution functions</h1>\n",
    "Execute functions to generate statistics, and create a GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>perform calculations to generate all message statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_calculations():\n",
    "    global content_sums\n",
    "    content_sums = calculate_content_sums()\n",
    "    global word_sums\n",
    "    word_sums = calculate_word_sums()\n",
    "    global messages_by_hour\n",
    "    messages_by_hour = get_messages_by_hour()\n",
    "    global occurrences\n",
    "    occurrences = calculate_occurrences()\n",
    "    global sentiment\n",
    "    sentiment = calculate_sentiment()\n",
    "    global word_ranking\n",
    "    word_ranking = calculate_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>draw all plots selected for display</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = {\"Content\":plot_content,\"Average Content\":plot_average_content,\"Messages by Hour\":plot_messages_by_hour,\"Occurrences\":plot_occurrences,\"Sentiment\":plot_sentiment,\"Words\":plot_words}\n",
    "\n",
    "def draw_plots():\n",
    "    with out:\n",
    "        display_plots = [plots[checkbox.description] for checkbox in plot_checkboxes if checkbox.value==True]\n",
    "        if(len(display_plots)!=0): # draw every selected plot\n",
    "            clear_output(wait=True)\n",
    "            for plot in display_plots:\n",
    "                plot()\n",
    "        else: # clear plots and don't draw anything\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>GUI and execution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(): # set values of variables used for creating plots to repsective widget states\n",
    "    global display_authors\n",
    "    display_authors = [checkbox.description for checkbox in author_checkboxes if checkbox.value==True]\n",
    "    global display_media\n",
    "    display_media = [checkbox.description for checkbox in media_checkboxes if checkbox.value==True]\n",
    "    global display_content\n",
    "    display_content = [\"Message\" if message_checkbox.value==True else None] + display_media\n",
    "    global timescale\n",
    "    timescale = timescale_buttons.value\n",
    "    global date_range\n",
    "    date_range = date_slider.value\n",
    "    global search, search_type\n",
    "    search = occurrences_box.value\n",
    "    search_type = occurrences_type.value\n",
    "    global word_type, display_amount\n",
    "    word_type = word_type_box.value\n",
    "    display_amount = int(word_display_box.value) if word_display_box.value!=\"\" else 10\n",
    "\n",
    "\n",
    "def apply_clicked(b): # execute plotting upon button click\n",
    "    new_search = True if occurrences_box.value!=search else False # perform a new occurrences calculation if new value input\n",
    "    new_words = True if word_type != word_type_box.value or date_range != date_slider.value else False # perform a new words calculation if different word type or date change\n",
    "    set_values()\n",
    "    if(new_search):\n",
    "        global occurrences\n",
    "        occurrences = calculate_occurrences()\n",
    "    if(new_words):\n",
    "        global word_ranking, total_word_ranking\n",
    "        word_ranking = calculate_words()\n",
    "\n",
    "    draw_plots()\n",
    "\n",
    "apply = Button(description=\"Apply\")\n",
    "apply.on_click(apply_clicked)\n",
    "\n",
    "\n",
    "plot_checkboxes = []\n",
    "for plot in plots.keys():\n",
    "    plot_checkboxes.append(Checkbox(value=False, description=plot, disabled=False, indent=False, layout=Layout(width='150px')))\n",
    "plot_container = VBox([Label(\"Select Plots\")]+plot_checkboxes)\n",
    "\n",
    "\n",
    "author_checkboxes = []\n",
    "for author in authors:\n",
    "    author_checkboxes.append(Checkbox(value=True, description=author, disabled=False, indent=False, layout=Layout(width='150px')))\n",
    "author_container = VBox([Label(\"Display Authors\")]+author_checkboxes)\n",
    "\n",
    "\n",
    "def change_timescale(change):\n",
    "    global timescale\n",
    "    timescale = timescale_buttons.value\n",
    "\n",
    "    date_slider.min=0\n",
    "    date_slider.max=len(dates[timescale])-1\n",
    "    date_slider.value = (0, len(dates[timescale])-1)\n",
    "    \n",
    "    date_readout.value = slider_readout()\n",
    "\n",
    "timescale_buttons = RadioButtons(options=[\"Days\",\"Weeks\",\"Months\",\"Years\"],layout=Layout(width='150px'))\n",
    "timescale_buttons.observe(change_timescale, names=\"value\")\n",
    "timescale_container = VBox([Label(\"Timescale\"),timescale_buttons])\n",
    "\n",
    "\n",
    "media_checkboxes = []\n",
    "for media in medias.values():\n",
    "    media_checkboxes.append(Checkbox(value=True, description=media, disabled=False, indent=False, layout=Layout(width='150px')))\n",
    "message_checkbox = Checkbox(value=True, description=\"Message\", disabled=False, indent=False, layout=Layout(width='150px'))\n",
    "content_container = VBox([Label(\"Content Types\")]+[message_checkbox]+media_checkboxes)\n",
    "\n",
    "\n",
    "occurrences_box = Text(value='', placeholder=\"Search Key\", layout=Layout(width='150px'))\n",
    "occurrences_type = RadioButtons(options=[\"Absolute\",\"Ratio\"])\n",
    "occurrences_container = VBox([Label(\"Occurrences Settings\")]+[occurrences_box,occurrences_type])\n",
    "\n",
    "word_display_box = Text(value='', placeholder=\"Display Amount\", layout=Layout(width='150px'))\n",
    "word_type_box = RadioButtons(options=[\"Frequency\",\"Representativeness\"])\n",
    "words_container = VBox([Label(\"Words Settings\")]+[word_display_box,word_type_box])\n",
    "\n",
    "settings_container = VBox([occurrences_container,words_container])\n",
    "\n",
    "\n",
    "toolbar = HBox([apply,plot_container,author_container,timescale_container,content_container,settings_container])\n",
    "\n",
    "\n",
    "def slider_readout():\n",
    "    if(timescale==\"Days\" or timescale==\"Weeks\"): # date shown as YY-MM-DD\n",
    "        return str(dates[timescale][date_slider.value[0]]) + \" - \" + str(dates[timescale][date_slider.value[1]])\n",
    "    elif(timescale==\"Months\"):\n",
    "        return str(dates[timescale][date_slider.value[0]])[:-3] + \" - \" + str(dates[timescale][date_slider.value[1]])[:-3]\n",
    "    elif(timescale==\"Years\"):\n",
    "        return str(dates[timescale][date_slider.value[0]])[:-6] + \" - \" + str(dates[timescale][date_slider.value[1]])[:-6]\n",
    "\n",
    "def slider_change(*args):\n",
    "    date_readout.value = slider_readout()\n",
    "\n",
    "date_slider = IntRangeSlider( value=[0, len(dates[\"Days\"])-1], min=0, max=len(dates[\"Days\"])-1, continuous_update=True, readout=False, layout=Layout(width='1030px'))\n",
    "date_slider.observe(slider_change, names='value')\n",
    "date_readout = Label(str(dates[\"Days\"][0]) + \" - \" + str(dates[\"Days\"][-1]))\n",
    "date_range_container = HBox([date_readout,date_slider])\n",
    "\n",
    "\n",
    "out = Output()\n",
    "display(toolbar,date_range_container,out)\n",
    "set_values()\n",
    "perform_calculations()\n",
    "draw_plots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
